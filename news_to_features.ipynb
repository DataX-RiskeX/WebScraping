{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Packages and Libraries ##\n",
    "\n",
    "# Web parcing, scraping, etc.\n",
    "import bs4 as bs # BeautifulSoup4 \n",
    "import urllib3\n",
    "import re\n",
    "import requests # HTTP parser\n",
    "import html5lib\n",
    "\n",
    "# DataFrames and math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Output related packages \n",
    "import pprint as pp\n",
    "import json\n",
    "\n",
    "# Progress bar and delaying requests \n",
    "from tqdm import tnrange, tqdm_notebook #progress bars\n",
    "from random import randint\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# stretch Jupyter coding blocks to fit screen\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\")) \n",
    "\n",
    "# make it run on py2 and py3\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining I\n",
    "This  notebook is intended to perform the following processes:\n",
    "\n",
    "    1.1 Read-in news articles from newsAPI for a given date range, and up to five queries (passed as a list).\n",
    "\n",
    "    1.2 Extract features native to the articles (e.g. url).\n",
    "\n",
    "    1.3 Perform data cleanup and preprocessing.\n",
    "\n",
    "    1.4 Split dataset into n-csv-files for distrubuted computation or batching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### **Begin Data Mining I:** Read-in NewsAPI feed for a given date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'newsapi.newsapi_client.NewsApiClient'>\n"
     ]
    }
   ],
   "source": [
    "### NEWSAPI RELATED ###\n",
    "# keys: \n",
    "mkey = '8ba091b7a47b4c9a9162a83ca72eb1ca'\n",
    "ekey = '2bc85776a0c14af6b9937366ad683e2f'\n",
    "\n",
    "# Install API \n",
    "#!pip install newsapi-python\n",
    "\n",
    "# Import Client\n",
    "from newsapi import NewsApiClient\n",
    "\n",
    "# Initialize Client (create object)\n",
    "news_api = NewsApiClient(api_key = mkey)\n",
    "print(type(news_api))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.1 Read-in news articles from newsAPI for a given date range__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: **get_news**\n",
    "Function establishes values to be used for control of loop then calls functions used to extract news article data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(query, start, stop, sort, lang, article_count, page_count):\n",
    "    import math\n",
    "    # extract information about response file to ensure proper loop control\n",
    "    params = get_params(query, start, stop, sort, lang, article_count, page_count)\n",
    "\n",
    "    # variable referencing\n",
    "    status = params['status']\n",
    "    results = params['totalResults']\n",
    "    \n",
    "    # Confirmation of data extraction\n",
    "    print(\"\\nVerify Read-in Process:\", status)\n",
    "    print(\"Number of Articles Correctly Extracted: \", results)\n",
    "    print(type(params), params.keys())\n",
    "           \n",
    "    # per page article extraction stop variable -- if number of articles is greater than number articles per page\n",
    "    loops = math.ceil(results/article_count)\n",
    "    \n",
    "    if page_count == 'all' or article_count <  results:\n",
    "        print(\"\\n\\nExtracting News Data...\\n\")\n",
    "        news_df = pd.DataFrame()\n",
    "        # function is called withinin loop, is subject to number of pages available as a function of total no. articles\n",
    "        for page in range(loops):\n",
    "            page = page + 1\n",
    "            df = news_data(query, start, stop, sort, lang, article_count, page_count)\n",
    "            news_df = news_df.append(df)  #'.append' does not happen in place, so variable assignment stores dataframes    \n",
    "        print(\"Process Completed.\")\n",
    "        return(news_df)            \n",
    "    else:\n",
    "        print(\"Invalid Parameters: Check values\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: **get_params**\n",
    "Function runs an initial newsAPI call, used to store values for controlling loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vanilla function for reading all articles, subject to parameters. \n",
    "# Can be used alone, or to extract values for iteration control.\n",
    "def get_params(query, start, stop, sort, lang, article_count, page_count):\n",
    "    print(\"\\nExtracting Parameters for newsAPI...\\n\")\n",
    "    params = news_api.get_everything(q = query,\n",
    "                                     from_parameter= start,\n",
    "                                     to= stop,\n",
    "                                     sort_by= sort,\n",
    "                                     language= lang,\n",
    "                                     page_size= int(article_count)\n",
    "                                    )\n",
    "    \n",
    "    # Confirmation of data extraction\n",
    "    print(\"Read-in Status of Given Date Range:\", params['status'])\n",
    "    print(\"Number of Articles in Given Date Range: \", params['totalResults'])\n",
    "    \n",
    "    return(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: **news_data**\n",
    "Function handles cases, and extracts values within 'articles'. Returns dataframe of contents: \n",
    "\n",
    "\n",
    "*Index(['author', 'description', 'publishedAt', 'source', 'title', 'url','urlToImage'],dtype='object')*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function can handle various relationships between no.pages and no.articles\n",
    "def news_data(query, start, stop, sort, lang, article_count, page_count):\n",
    "    if page_count == 'all':\n",
    "        params = news_api.get_everything(q = query,\n",
    "                                         from_parameter= start,\n",
    "                                         to= stop,\n",
    "                                         sort_by= sort,\n",
    "                                         language= lang,\n",
    "                                         page_size= int(article_count)\n",
    "                                         )\n",
    "    else: \n",
    "        params = news_api.get_everything(q = query,\n",
    "                                         from_parameter= start,\n",
    "                                         to= stop,\n",
    "                                         sort_by= sort,\n",
    "                                         language= lang,\n",
    "                                         page_size= int(article_count),\n",
    "                                         page = int(page_count)\n",
    "                                         )\n",
    "    values = pd.DataFrame(params['articles'])\n",
    "    return(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User provided parameters and function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#01/26/18 to 03/26/18\n",
    "query = 'Bitcoin'         # can handle a list of up to five search topics\n",
    "start = '2018-01-26'      # yyyy-mm-dd\n",
    "stop = '2018-03-26'\n",
    "sort = 'publishedAt'\n",
    "lang = 'en'\n",
    "article_count = int(100)  # default is 20\n",
    "page_count = 'all'        # enter 1, 2, ... Notes: 'all' iterates over all articLes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Parameters for newsAPI...\n",
      "\n",
      "Read-in Status of Given Date Range: ok\n",
      "Number of Articles in Given Date Range:  24773\n",
      "\n",
      "Verify Read-in Process: ok\n",
      "Number of Articles Correctly Extracted:  24773\n",
      "<class 'dict'> dict_keys(['status', 'totalResults', 'articles'])\n",
      "\n",
      "\n",
      "Extracting News Data...\n",
      "\n",
      "Process Completed.\n"
     ]
    }
   ],
   "source": [
    "# object is the result of the following functions: 'get_params', 'get_news', and 'get_data'\n",
    "news = get_news(query, start, stop, sort, lang, article_count, page_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore nested key/value pairs from newsAPI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24800\n",
      "Index(['author', 'description', 'publishedAt', 'source', 'title', 'url',\n",
      "       'urlToImage'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>description</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>urlToImage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cecchetti, Schoenholtz</td>\n",
       "      <td>Despite recent technological advances, the cos...</td>\n",
       "      <td>2018-03-27T00:00:00Z</td>\n",
       "      <td>{'id': None, 'name': 'Voxeu.org'}</td>\n",
       "      <td>The stubbornly high cost of remittances</td>\n",
       "      <td>https://voxeu.org/article/stubbornly-high-cost...</td>\n",
       "      <td>https://voxeu.org/sites/default/files/image/Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reuters</td>\n",
       "      <td>Twitter Inc will start banning cryptocurrency ...</td>\n",
       "      <td>2018-03-26T23:43:50Z</td>\n",
       "      <td>{'id': None, 'name': 'Cio.com.au'}</td>\n",
       "      <td>Twitter to ban cryptocurrency ads</td>\n",
       "      <td>https://www.cio.com.au/article/635378/twitter-...</td>\n",
       "      <td>https://d2r9nfiii89r0l.cloudfront.net/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>See more 'Bitcoin' images on Know Your Meme!</td>\n",
       "      <td>2018-03-26T23:36:52Z</td>\n",
       "      <td>{'id': None, 'name': 'Knowyourmeme.com'}</td>\n",
       "      <td>Bitcoin | c71.jpg</td>\n",
       "      <td>http://knowyourmeme.com/photos/1355307-bitcoin</td>\n",
       "      <td>http://i0.kym-cdn.com/photos/images/facebook/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>James Mickleboro</td>\n",
       "      <td>The bitcoin (BTC) price has bounced back from ...</td>\n",
       "      <td>2018-03-26T23:35:38Z</td>\n",
       "      <td>{'id': None, 'name': 'Fool.com.au'}</td>\n",
       "      <td>Why the bitcoin (BTC) price was smashed overnight</td>\n",
       "      <td>https://www.fool.com.au/2018/03/27/why-the-bit...</td>\n",
       "      <td>https://www.fool.com.au/wp-content/uploads/201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>newsfeeds@nzherald.co.nz</td>\n",
       "      <td>NEW YORK (AP) — Twitter says it will ban or re...</td>\n",
       "      <td>2018-03-26T23:25:06Z</td>\n",
       "      <td>{'id': None, 'name': 'Nzherald.co.nz'}</td>\n",
       "      <td>Twitter to ban cryptocurrency ads, joining Fac...</td>\n",
       "      <td>http://www.nzherald.co.nz/business/news/articl...</td>\n",
       "      <td>/pb/resources/assets/img/fallback-promo-image....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     author  \\\n",
       "0    Cecchetti, Schoenholtz   \n",
       "1                   Reuters   \n",
       "2                      None   \n",
       "3          James Mickleboro   \n",
       "4  newsfeeds@nzherald.co.nz   \n",
       "\n",
       "                                         description           publishedAt  \\\n",
       "0  Despite recent technological advances, the cos...  2018-03-27T00:00:00Z   \n",
       "1  Twitter Inc will start banning cryptocurrency ...  2018-03-26T23:43:50Z   \n",
       "2       See more 'Bitcoin' images on Know Your Meme!  2018-03-26T23:36:52Z   \n",
       "3  The bitcoin (BTC) price has bounced back from ...  2018-03-26T23:35:38Z   \n",
       "4  NEW YORK (AP) — Twitter says it will ban or re...  2018-03-26T23:25:06Z   \n",
       "\n",
       "                                     source  \\\n",
       "0         {'id': None, 'name': 'Voxeu.org'}   \n",
       "1        {'id': None, 'name': 'Cio.com.au'}   \n",
       "2  {'id': None, 'name': 'Knowyourmeme.com'}   \n",
       "3       {'id': None, 'name': 'Fool.com.au'}   \n",
       "4    {'id': None, 'name': 'Nzherald.co.nz'}   \n",
       "\n",
       "                                               title  \\\n",
       "0            The stubbornly high cost of remittances   \n",
       "1                  Twitter to ban cryptocurrency ads   \n",
       "2                                  Bitcoin | c71.jpg   \n",
       "3  Why the bitcoin (BTC) price was smashed overnight   \n",
       "4  Twitter to ban cryptocurrency ads, joining Fac...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://voxeu.org/article/stubbornly-high-cost...   \n",
       "1  https://www.cio.com.au/article/635378/twitter-...   \n",
       "2     http://knowyourmeme.com/photos/1355307-bitcoin   \n",
       "3  https://www.fool.com.au/2018/03/27/why-the-bit...   \n",
       "4  http://www.nzherald.co.nz/business/news/articl...   \n",
       "\n",
       "                                          urlToImage  \n",
       "0  https://voxeu.org/sites/default/files/image/Fr...  \n",
       "1  https://d2r9nfiii89r0l.cloudfront.net/article/...  \n",
       "2  http://i0.kym-cdn.com/photos/images/facebook/0...  \n",
       "3  https://www.fool.com.au/wp-content/uploads/201...  \n",
       "4  /pb/resources/assets/img/fallback-promo-image....  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(news))\n",
    "print(news.keys())\n",
    "news.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.2 Extract features native to the articles__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: **get_info**\n",
    "Function extracts variables from dataframe and stores each as a list, returning all of them as a single dataframe.\n",
    "\n",
    "__Note:__ *urlToImage* is not included in this process, as we are uncertain as to the value of the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_info(df):\n",
    "    # for deepcopy()\n",
    "    import copy\n",
    "    \n",
    "    author = []\n",
    "    title = []\n",
    "    publisher = []\n",
    "    publish_url = []\n",
    "    timeStamp = []\n",
    "    description = []\n",
    "    \n",
    "    # loop appends rows to respective lists \n",
    "    for col_name in df:\n",
    "        for index in df[col_name]:\n",
    "            if col_name == 'author':\n",
    "                author.append(index)\n",
    "            elif col_name == 'title':\n",
    "                title.append(index)\n",
    "            elif col_name == 'source':\n",
    "                name = index['name']\n",
    "                publisher.append(name)\n",
    "            elif col_name == 'url':\n",
    "                publish_url.append(index)\n",
    "            elif col_name == 'publishedAt':\n",
    "                timeStamp.append(index)\n",
    "            elif col_name == 'description':\n",
    "                description.append(index)\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "    # merge lists and return them as dataframe.\n",
    "    df = pd.DataFrame({'author' : author,\n",
    "                       'title' : title,\n",
    "                       'publisher' : publisher,\n",
    "                       'source_url' : publish_url,\n",
    "                       'timeStamp' : timeStamp,\n",
    "                       'description' : description})\n",
    "    \n",
    "    return(df)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Completed newsAPI Read-in Process: \n",
    "##### newsDF contains features extracted from raw newsAPI feed, for a given data range, and query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object creation\n",
    "newsDF = get_info(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Dimensions: (24800, 6) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>description</th>\n",
       "      <th>publisher</th>\n",
       "      <th>source_url</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cecchetti, Schoenholtz</td>\n",
       "      <td>Despite recent technological advances, the cos...</td>\n",
       "      <td>Voxeu.org</td>\n",
       "      <td>https://voxeu.org/article/stubbornly-high-cost...</td>\n",
       "      <td>2018-03-27T00:00:00Z</td>\n",
       "      <td>The stubbornly high cost of remittances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reuters</td>\n",
       "      <td>Twitter Inc will start banning cryptocurrency ...</td>\n",
       "      <td>Cio.com.au</td>\n",
       "      <td>https://www.cio.com.au/article/635378/twitter-...</td>\n",
       "      <td>2018-03-26T23:43:50Z</td>\n",
       "      <td>Twitter to ban cryptocurrency ads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>See more 'Bitcoin' images on Know Your Meme!</td>\n",
       "      <td>Knowyourmeme.com</td>\n",
       "      <td>http://knowyourmeme.com/photos/1355307-bitcoin</td>\n",
       "      <td>2018-03-26T23:36:52Z</td>\n",
       "      <td>Bitcoin | c71.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   author                                        description  \\\n",
       "0  Cecchetti, Schoenholtz  Despite recent technological advances, the cos...   \n",
       "1                 Reuters  Twitter Inc will start banning cryptocurrency ...   \n",
       "2                    None       See more 'Bitcoin' images on Know Your Meme!   \n",
       "\n",
       "          publisher                                         source_url  \\\n",
       "0         Voxeu.org  https://voxeu.org/article/stubbornly-high-cost...   \n",
       "1        Cio.com.au  https://www.cio.com.au/article/635378/twitter-...   \n",
       "2  Knowyourmeme.com     http://knowyourmeme.com/photos/1355307-bitcoin   \n",
       "\n",
       "              timeStamp                                    title  \n",
       "0  2018-03-27T00:00:00Z  The stubbornly high cost of remittances  \n",
       "1  2018-03-26T23:43:50Z        Twitter to ban cryptocurrency ads  \n",
       "2  2018-03-26T23:36:52Z                        Bitcoin | c71.jpg  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying correct data extraction\n",
    "print(\"\\nDataFrame Dimensions:\", newsDF.shape, \"\\n\")\n",
    "newsDF.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.3 Perform data cleanup and preprocessing.__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions perform basic clean up on a dataframe. The purpose is to prepare the file to write-out (csv).  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'None' values\n",
    "def findNone(df):\n",
    "    \"\"\"\n",
    "     Receives pandas datraframe, and removes null entries from author feature\n",
    "    \"\"\"\n",
    "    print(\"Removing 'None' values in author feature...\")\n",
    "    author = df['author']\n",
    "    publisher = df['publisher']\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        if pd.isnull(author.loc[i]):\n",
    "            author.loc[i] = publisher.loc[i]\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove gaps \n",
    "def gapStrip(df):\n",
    "    \"\"\"\n",
    "    Receives pandas dataframe and leading and traling empty space`\n",
    "    \"\"\"\n",
    "    df.columns = map(str.strip, df.columns) \n",
    "    print(\"Removing leading and trailing spaces and tabs...\")\n",
    "    # element-wise operation\n",
    "    f = lambda x: x.strip() if (isinstance(x,str)) else x\n",
    "    df = df.applymap(f)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize time stamps\n",
    "def std_timeStamp(df):\n",
    "    \"\"\"\n",
    "    Receives pandas dataframe and standardizes time stamps \n",
    "    \"\"\"\n",
    "    import datetime\n",
    "    # Check to see time stamps are in zero timezones\n",
    "    print(\"Converting Time Stamps to Desired Standard Formating...\")\n",
    "    for time in df['timeStamp']:\n",
    "        if time.endswith('Z'):\n",
    "            df['timeStamp'] = pd.to_datetime(df['timeStamp'],\n",
    "                                             infer_datetime_format = True,\n",
    "                                             utc = True)                       # returns a type '.Timestamp'\n",
    "            return(df)\n",
    "        else:\n",
    "            print(\"Revisit appropriate variable or function to deal with time zones that are not zero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_clean(df):\n",
    "    \"\"\"\n",
    "    Performs Generic Cleanup and Preprocessing on a given dataframe sourced from newsAPI\n",
    "    \"\"\"\n",
    "    temp = findNone(df)           # removes missing values from author column\n",
    "    temp2 = gapStrip(temp)        # remove leading and trailing white space\n",
    "    temp3 = std_timeStamp(temp2)  # convert time stamps to 'utc' standard\n",
    "    return(temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 'None' values in author feature...\n",
      "Removing leading and trailing spaces and tabs...\n",
      "Converting Time Stamps to Desired Standard Formating...\n"
     ]
    }
   ],
   "source": [
    "riskEx_df = feature_clean(newsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>description</th>\n",
       "      <th>publisher</th>\n",
       "      <th>source_url</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24795</th>\n",
       "      <td>Anna Hensel</td>\n",
       "      <td>Twitter, following in the footsteps of Google ...</td>\n",
       "      <td>Venturebeat.com</td>\n",
       "      <td>https://venturebeat.com/2018/03/26/twitter-to-...</td>\n",
       "      <td>2018-03-26 18:36:42+00:00</td>\n",
       "      <td>Twitter to start banning cryptocurrency ads, j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24796</th>\n",
       "      <td>Camila Russo</td>\n",
       "      <td>Cryptocurrency exchanges and wallet services a...</td>\n",
       "      <td>Livemint.com</td>\n",
       "      <td>https://www.livemint.com/Industry/XpaNirgkBbmC...</td>\n",
       "      <td>2018-03-26 18:30:47+00:00</td>\n",
       "      <td>Twitter joins Facebook, Google in banning cryp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24797</th>\n",
       "      <td>Bram de Haas</td>\n",
       "      <td>Bitcoin has crashed pretty badly since the end...</td>\n",
       "      <td>Seekingalpha.com</td>\n",
       "      <td>https://seekingalpha.com/article/4158925-buy-b...</td>\n",
       "      <td>2018-03-26 18:21:07+00:00</td>\n",
       "      <td>Why Buy Bitcoin At $8,169.80?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24798</th>\n",
       "      <td>Financial Times</td>\n",
       "      <td>Social media sites are under pressure to prote...</td>\n",
       "      <td>Financial Times</td>\n",
       "      <td>https://www.ft.com/content/bddd293a-3118-11e8-...</td>\n",
       "      <td>2018-03-26 18:18:25+00:00</td>\n",
       "      <td>Twitter cracks down on cryptocurrency ads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24799</th>\n",
       "      <td>Michelle Meyers</td>\n",
       "      <td>As was expected, the company joins Facebook an...</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>https://www.cnet.com/news/twitter-confirms-its...</td>\n",
       "      <td>2018-03-26 18:17:15+00:00</td>\n",
       "      <td>Twitter confirms it's banning cryptocurrency a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author                                        description  \\\n",
       "24795      Anna Hensel  Twitter, following in the footsteps of Google ...   \n",
       "24796     Camila Russo  Cryptocurrency exchanges and wallet services a...   \n",
       "24797     Bram de Haas  Bitcoin has crashed pretty badly since the end...   \n",
       "24798  Financial Times  Social media sites are under pressure to prote...   \n",
       "24799  Michelle Meyers  As was expected, the company joins Facebook an...   \n",
       "\n",
       "              publisher                                         source_url  \\\n",
       "24795   Venturebeat.com  https://venturebeat.com/2018/03/26/twitter-to-...   \n",
       "24796      Livemint.com  https://www.livemint.com/Industry/XpaNirgkBbmC...   \n",
       "24797  Seekingalpha.com  https://seekingalpha.com/article/4158925-buy-b...   \n",
       "24798   Financial Times  https://www.ft.com/content/bddd293a-3118-11e8-...   \n",
       "24799          Cnet.com  https://www.cnet.com/news/twitter-confirms-its...   \n",
       "\n",
       "                      timeStamp  \\\n",
       "24795 2018-03-26 18:36:42+00:00   \n",
       "24796 2018-03-26 18:30:47+00:00   \n",
       "24797 2018-03-26 18:21:07+00:00   \n",
       "24798 2018-03-26 18:18:25+00:00   \n",
       "24799 2018-03-26 18:17:15+00:00   \n",
       "\n",
       "                                                   title  \n",
       "24795  Twitter to start banning cryptocurrency ads, j...  \n",
       "24796  Twitter joins Facebook, Google in banning cryp...  \n",
       "24797                      Why Buy Bitcoin At $8,169.80?  \n",
       "24798          Twitter cracks down on cryptocurrency ads  \n",
       "24799  Twitter confirms it's banning cryptocurrency a...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking\n",
    "riskEx_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24800 entries, 0 to 24799\n",
      "Data columns (total 6 columns):\n",
      "author         24800 non-null object\n",
      "description    24800 non-null object\n",
      "publisher      24800 non-null object\n",
      "source_url     24800 non-null object\n",
      "timeStamp      24800 non-null datetime64[ns, UTC]\n",
      "title          24800 non-null object\n",
      "dtypes: datetime64[ns, UTC](1), object(5)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "## Check file size\n",
    "riskEx_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.4 Write out to csv.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out n-csv-files each with 100 rows. Process is done to reduce computational load\n",
    "riskEx_df.to_csv('rawData.csv', index_label = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ if wanting to create batches of raw data files, use the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def df_to_csvs(df):\n",
    "#    articlesPage = int(100)\n",
    "#    totalArticles = len(df)\n",
    "#    batchSize=round(totalArticles/articlesPage)          # number of rows in single output file\n",
    "        \n",
    "#    for id, df_i in  enumerate(np.array_split(df, batchSize)):\n",
    "#        df_i.to_csv('rawData_{id}.csv'.format(id=id), index_label = False)                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **End Data Mining I:** Read-in NewsAPI feed for a given date range\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
